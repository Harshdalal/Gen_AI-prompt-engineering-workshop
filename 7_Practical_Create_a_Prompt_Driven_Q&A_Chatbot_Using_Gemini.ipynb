{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üß™ Practical: Create a Prompt-Driven Q&A Chatbot Using Gemini\n",
        "\n",
        "#‚úÖ Objective\n",
        "\n",
        "This chatbot:\n",
        "\n",
        "Accepts user input as questions\n",
        "\n",
        "Dynamically constructs prompts\n",
        "\n",
        "Uses Gemini (gemini-1.5-flash-latest) for fast and smart responses\n"
      ],
      "metadata": {
        "id": "oi0bhg_T7ZwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 1: Install Gemini SDK"
      ],
      "metadata": {
        "id": "eCDg__ph7Ztd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "j-g5nrY557kB"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 2: Import Libraries and Configure Gemini API"
      ],
      "metadata": {
        "id": "pD0Tl8eM8G3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "# Configure Gemini with your API key\n",
        "genai.configure(api_key=\"AIzaSyCOQXtLBKUXIlw4p-jarVeENvtvmnBPLiw\")  # Replace with your actual key\n"
      ],
      "metadata": {
        "id": "ydpFQ-m07aOv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 3: Load the Multimodal Gemini Model"
      ],
      "metadata": {
        "id": "OhnBJQt08I2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use fast multimodal model\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash-latest\")\n"
      ],
      "metadata": {
        "id": "itlKMUde7g8Q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 4: Create a Prompt Template for Q&A"
      ],
      "metadata": {
        "id": "_Wb1sgGm8LLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Constructs a prompt for Q&A based on the user's question.\n",
        "    \"\"\"\n",
        "    return f\"\"\"You are a helpful assistant. Answer the following question clearly and concisely.\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n"
      ],
      "metadata": {
        "id": "DnXTUjNO7iaM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 5: Define a Q&A Function\n",
        "\n"
      ],
      "metadata": {
        "id": "Mex8zAJQ8QHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Sends the formatted prompt to Gemini and returns the answer.\n",
        "    \"\"\"\n",
        "    prompt = build_prompt(question)\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n"
      ],
      "metadata": {
        "id": "YfHwQb9-7zIN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 6: Test with a Single Question"
      ],
      "metadata": {
        "id": "YDXP7vuD8SzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the difference between AI and  gen ai , give me short answer?\"\n",
        "answer = ask_question(question)\n",
        "\n",
        "print(\"‚ùì Question:\", question)\n",
        "print(\"üí¨ Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "ukBc6s5I708N",
        "outputId": "0c5faee1-4e2e-4a09-e058-c3f65ac7abae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Question: What is the difference between AI and  gen ai , give me short answer?\n",
            "üí¨ Answer: AI is a broad field encompassing any technique that enables computers to mimic human intelligence.  Generative AI (Gen AI) is a *subset* of AI that focuses on creating new content, like text, images, or code, rather than just analyzing existing data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 7: Build a Simple Interactive Loop (Text Chat)"
      ],
      "metadata": {
        "id": "K71UQ4Nz8VZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ü§ñ Welcome to the Gemini Q&A Chatbot! (Type 'exit' to quit)\")\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"You: \")\n",
        "    if user_question.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "    answer = ask_question(user_question)\n",
        "    print(\"Gemini:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoGuj2gJ72ud",
        "outputId": "4d33c0ef-8c7f-44bf-e557-7fae0ce98c5b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Welcome to the Gemini Q&A Chatbot! (Type 'exit' to quit)\n",
            "You: quit\n",
            "üëã Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#implement on gradio chatbot"
      ],
      "metadata": {
        "id": "Cxav3W6NGeE8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S27Px_8TE5pT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwx9V4agFa57"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#gradio chatbot"
      ],
      "metadata": {
        "id": "LrU5u3wvGZQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def build_prompt(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Wraps user input into a consistent Q&A prompt.\n",
        "    \"\"\"\n",
        "    return f\"\"\"You are a helpful assistant. Answer the following question clearly and concisely.\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "def gemini_qa(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Sends the prompt to Gemini and returns the response.\n",
        "    \"\"\"\n",
        "    if not question.strip():\n",
        "        return \"Please enter a question.\"\n",
        "\n",
        "    prompt = build_prompt(question)\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Error: {e}\"\n",
        "\n",
        "# Create the Gradio app\n",
        "interface = gr.Interface(\n",
        "    fn=gemini_qa,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Ask a question...\"),\n",
        "    outputs=gr.Textbox(label=\"Gemini's Answer\"),\n",
        "    title=\"üß† Gemini Q&A Chatbot\",\n",
        "    description=\"Ask anything! Powered by Gemini Flash.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "avICT36vFswQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "jFNHEuhSFduS",
        "outputId": "99695e0b-f7cd-4138-96f2-aaedd5ee2d1a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8aebeeb78e56c6ad5f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8aebeeb78e56c6ad5f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yB-map-UFudK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}